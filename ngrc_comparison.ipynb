{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGRC vs Fourier vs Traditional Reservoir for INR\n",
    "\n",
    "Comparing Next Generation Reservoir Computing (NGRC) approach with Fourier features and traditional reservoir computing for Implicit Neural Representations.\n",
    "\n",
    "**Key Insight**: NGRC uses polynomial features of time-delayed inputs instead of random recurrent dynamics. For spatial INR, we adapt this to polynomial features of spatial coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    USE_TORCH = True\n",
    "    print(\"PyTorch available for MLP training\")\n",
    "except ImportError:\n",
    "    USE_TORCH = False\n",
    "    print(\"PyTorch not available, using Ridge regression only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess image\n",
    "img = Image.open('fig/cat.png').convert('RGB')\n",
    "target_size = 256\n",
    "img = img.resize((target_size, target_size), Image.LANCZOS)\n",
    "img_array = np.array(img) / 255.0\n",
    "\n",
    "h, w, c = img_array.shape\n",
    "print(f\"Image size: {h}x{w}x{c}\")\n",
    "\n",
    "# Create coordinate grid\n",
    "coords = np.linspace(0, 1, h, endpoint=False)\n",
    "x_grid = np.stack(np.meshgrid(coords, coords), -1)  # (H, W, 2)\n",
    "\n",
    "# Train/test split (as in original Fourier paper)\n",
    "test_data = (x_grid.reshape(-1, 2), img_array.reshape(-1, 3))\n",
    "train_data = (x_grid[::2, ::2].reshape(-1, 2), img_array[::2, ::2].reshape(-1, 3))\n",
    "\n",
    "print(f\"Train: {len(train_data[0])}, Test: {len(test_data[0])}\")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img_array)\n",
    "plt.title(f'Target Image ({h}x{w})')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: NGRC-Style Polynomial Features\n",
    "\n",
    "Following the NGRC principle: instead of random recurrence, use **explicit polynomial features**.\n",
    "\n",
    "For spatial INR with coordinates $(x, y)$:\n",
    "$$\\mathbf{O}(x,y) = [1, x, y, x^2, xy, y^2, x^3, x^2y, xy^2, y^3, \\ldots]$$\n",
    "\n",
    "This is the spatial analog of NGRC's time-delay polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrc_polynomial_features(x, degree=2):\n",
    "    \"\"\"\n",
    "    NGRC-style polynomial features for spatial coordinates.\n",
    "    \n",
    "    For degree=2: [1, x, y, x², xy, y²]\n",
    "    For degree=3: [1, x, y, x², xy, y², x³, x²y, xy², y³]\n",
    "    etc.\n",
    "    \n",
    "    This is the spatial analog of NGRC's time-delay polynomial expansion.\n",
    "    \"\"\"\n",
    "    n, d = x.shape\n",
    "    features = [np.ones((n, 1))]  # Constant term\n",
    "    \n",
    "    for deg in range(1, degree + 1):\n",
    "        # All monomials of this degree\n",
    "        for powers in combinations_with_replacement(range(d), deg):\n",
    "            # powers is like (0,), (1,), (0,0), (0,1), (1,1), etc.\n",
    "            term = np.ones(n)\n",
    "            for p in powers:\n",
    "                term = term * x[:, p]\n",
    "            features.append(term.reshape(-1, 1))\n",
    "    \n",
    "    return np.hstack(features)\n",
    "\n",
    "\n",
    "def ngrc_polynomial_features_fast(x, degree=2):\n",
    "    \"\"\"\n",
    "    Faster implementation using sklearn-style polynomial expansion.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from sklearn.preprocessing import PolynomialFeatures\n",
    "        poly = PolynomialFeatures(degree=degree, include_bias=True)\n",
    "        return poly.fit_transform(x)\n",
    "    except ImportError:\n",
    "        return ngrc_polynomial_features(x, degree)\n",
    "\n",
    "\n",
    "# Test\n",
    "test_x = np.array([[0.5, 0.5]])\n",
    "for deg in [2, 3, 4, 5]:\n",
    "    feats = ngrc_polynomial_features_fast(test_x, deg)\n",
    "    print(f\"Degree {deg}: {feats.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Fourier Features (Original Paper)\n",
    "\n",
    "$$\\gamma(\\mathbf{v}) = [\\sin(2\\pi \\mathbf{B} \\mathbf{v}), \\cos(2\\pi \\mathbf{B} \\mathbf{v})]^T$$\n",
    "\n",
    "where $\\mathbf{B} \\sim \\mathcal{N}(0, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_features(x, num_features, sigma):\n",
    "    \"\"\"\n",
    "    Random Fourier features as in the original paper.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    B = np.random.randn(num_features, x.shape[1]) * sigma\n",
    "    x_proj = (2. * np.pi * x) @ B.T\n",
    "    return np.concatenate([np.sin(x_proj), np.cos(x_proj)], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Traditional Reservoir (What We Were Doing)\n",
    "\n",
    "$$\\mathbf{h}^{(l)} = \\tanh(\\mathbf{W}_{in}^{(l)} \\mathbf{h}^{(l-1)} + \\mathbf{W}_{hh}^{(l)} \\mathbf{h}^{(l)} + \\mathbf{b}^{(l)})$$\n",
    "\n",
    "Iterative settling with recurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_reservoir(x, hidden_size, num_layers=5, iterations=10, spectral_radius=0.9):\n",
    "    \"\"\"\n",
    "    Traditional deep reservoir with recurrence.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    n, d = x.shape\n",
    "    \n",
    "    layers = []\n",
    "    d_in = d\n",
    "    for layer in range(num_layers):\n",
    "        np.random.seed(42 + layer)\n",
    "        W_in = np.random.randn(d_in, hidden_size) * 0.5\n",
    "        W_hh = np.random.randn(hidden_size, hidden_size)\n",
    "        eig = np.abs(np.linalg.eigvals(W_hh)).max()\n",
    "        W_hh = W_hh * (spectral_radius / eig)\n",
    "        b = np.random.randn(hidden_size) * 0.1\n",
    "        layers.append((W_in, W_hh, b))\n",
    "        d_in = hidden_size\n",
    "    \n",
    "    all_states = []\n",
    "    for i in tqdm(range(n), desc='Reservoir', leave=False):\n",
    "        layer_input = x[i:i+1]\n",
    "        layer_states = []\n",
    "        \n",
    "        for W_in, W_hh, b in layers:\n",
    "            h = np.zeros(hidden_size)\n",
    "            for _ in range(iterations):\n",
    "                h = np.tanh(layer_input @ W_in + h @ W_hh + b).flatten()\n",
    "            layer_states.append(h)\n",
    "            layer_input = h.reshape(1, -1)\n",
    "        \n",
    "        all_states.append(np.concatenate(layer_states))\n",
    "    \n",
    "    return np.array(all_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: NGRC-Style Random Nonlinear Projection\n",
    "\n",
    "Recent NGRC variants use **random nonlinear projections** instead of explicit polynomials:\n",
    "$$\\mathbf{O}(x) = \\phi(\\mathbf{W} \\mathbf{x} + \\mathbf{b})$$\n",
    "\n",
    "where $\\phi$ is a nonlinearity. This is like a single-layer random network (no recurrence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_nonlinear_projection(x, num_features, nonlinearity='tanh'):\n",
    "    \"\"\"\n",
    "    NGRC-style random nonlinear projection (no recurrence).\n",
    "    Similar to Extreme Learning Machine / Random Kitchen Sink.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(x.shape[1], num_features) * np.sqrt(2.0 / x.shape[1])\n",
    "    b = np.random.randn(num_features) * 0.1\n",
    "    \n",
    "    proj = x @ W + b\n",
    "    \n",
    "    if nonlinearity == 'tanh':\n",
    "        return np.tanh(proj)\n",
    "    elif nonlinearity == 'relu':\n",
    "        return np.maximum(0, proj)\n",
    "    elif nonlinearity == 'sin':\n",
    "        return np.sin(proj)\n",
    "    else:\n",
    "        return proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(H_train, y_train, H_test, y_test, lamb=1e-6):\n",
    "    \"\"\"Ridge regression with evaluation.\"\"\"\n",
    "    W = np.linalg.solve(H_train.T @ H_train + lamb * np.eye(H_train.shape[1]), H_train.T @ y_train)\n",
    "    pred = np.clip(H_test @ W, 0, 1)\n",
    "    mse = np.mean((pred - y_test) ** 2)\n",
    "    psnr = -10 * np.log10(mse) if mse > 0 else 100\n",
    "    return pred, mse, psnr, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: NGRC Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NGRC-STYLE POLYNOMIAL FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for degree in [2, 3, 4, 5, 6, 7, 8, 10, 12, 15]:\n",
    "    H_train = ngrc_polynomial_features_fast(train_data[0], degree)\n",
    "    H_test = ngrc_polynomial_features_fast(test_data[0], degree)\n",
    "    \n",
    "    try:\n",
    "        pred, mse, psnr, W = ridge_regression(H_train, train_data[1], H_test, test_data[1])\n",
    "        results[f'ngrc_poly_d{degree}'] = {'pred': pred, 'mse': mse, 'psnr': psnr, 'dim': H_train.shape[1]}\n",
    "        print(f\"  Degree {degree:>2}: PSNR = {psnr:.2f} dB (dim={H_train.shape[1]})\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Degree {degree:>2}: FAILED - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Fourier Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FOURIER FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for num_feat in [128, 256, 512, 1024]:\n",
    "    for sigma in [1, 10, 100]:\n",
    "        H_train = fourier_features(train_data[0], num_feat, sigma)\n",
    "        H_test = fourier_features(test_data[0], num_feat, sigma)\n",
    "        \n",
    "        pred, mse, psnr, W = ridge_regression(H_train, train_data[1], H_test, test_data[1])\n",
    "        name = f'fourier_n{num_feat}_s{sigma}'\n",
    "        results[name] = {'pred': pred, 'mse': mse, 'psnr': psnr, 'dim': H_train.shape[1]}\n",
    "        print(f\"  n={num_feat:>4}, σ={sigma:>3}: PSNR = {psnr:.2f} dB (dim={H_train.shape[1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Random Nonlinear Projection (NGRC variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RANDOM NONLINEAR PROJECTION (NGRC-style, no recurrence)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for num_feat in [256, 512, 1024, 2048]:\n",
    "    for nonlin in ['tanh', 'relu', 'sin']:\n",
    "        H_train = random_nonlinear_projection(train_data[0], num_feat, nonlin)\n",
    "        H_test = random_nonlinear_projection(test_data[0], num_feat, nonlin)\n",
    "        \n",
    "        pred, mse, psnr, W = ridge_regression(H_train, train_data[1], H_test, test_data[1])\n",
    "        name = f'random_{nonlin}_n{num_feat}'\n",
    "        results[name] = {'pred': pred, 'mse': mse, 'psnr': psnr, 'dim': H_train.shape[1]}\n",
    "        print(f\"  {nonlin:>4}, n={num_feat:>4}: PSNR = {psnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Traditional Reservoir (for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRADITIONAL DEEP RESERVOIR (with recurrence)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for num_layers, hidden in [(5, 128), (10, 64)]:\n",
    "    name = f'reservoir_L{num_layers}_H{hidden}'\n",
    "    print(f\"  Computing {name}...\")\n",
    "    \n",
    "    H_train = deep_reservoir(train_data[0], hidden, num_layers=num_layers, iterations=10)\n",
    "    H_test = deep_reservoir(test_data[0], hidden, num_layers=num_layers, iterations=10)\n",
    "    \n",
    "    pred, mse, psnr, W = ridge_regression(H_train, train_data[1], H_test, test_data[1])\n",
    "    results[name] = {'pred': pred, 'mse': mse, 'psnr': psnr, 'dim': H_train.shape[1]}\n",
    "    print(f\"    PSNR = {psnr:.2f} dB (dim={H_train.shape[1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by PSNR\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1]['psnr'], reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL RESULTS (sorted by PSNR)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Method':<35} {'PSNR (dB)':<12} {'Dim':<8}\")\n",
    "print(\"-\" * 55)\n",
    "for name, r in sorted_results[:20]:  # Top 20\n",
    "    print(f\"{name:<35} {r['psnr']:<12.2f} {r['dim']:<8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best in each category\n",
    "categories = {\n",
    "    'NGRC Polynomial': [k for k in results if 'ngrc_poly' in k],\n",
    "    'Fourier': [k for k in results if 'fourier' in k],\n",
    "    'Random Projection': [k for k in results if 'random_' in k],\n",
    "    'Traditional Reservoir': [k for k in results if 'reservoir' in k],\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BEST IN EACH CATEGORY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_results = {}\n",
    "for cat, keys in categories.items():\n",
    "    if keys:\n",
    "        best_key = max(keys, key=lambda k: results[k]['psnr'])\n",
    "        best_results[cat] = best_key\n",
    "        r = results[best_key]\n",
    "        print(f\"{cat:<25}: {best_key:<30} PSNR = {r['psnr']:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "\n",
    "# Row 1: Best from each method\n",
    "axes[0, 0].imshow(img_array)\n",
    "axes[0, 0].set_title('Original', fontsize=12)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "for i, (cat, key) in enumerate(best_results.items()):\n",
    "    if i < 4:\n",
    "        pred = results[key]['pred'].reshape(h, w, 3)\n",
    "        axes[0, i+1].imshow(pred)\n",
    "        axes[0, i+1].set_title(f'{cat}\\n{results[key][\"psnr\"]:.1f} dB', fontsize=10)\n",
    "        axes[0, i+1].axis('off')\n",
    "\n",
    "# Row 2: NGRC polynomial scaling\n",
    "poly_keys = sorted([k for k in results if 'ngrc_poly' in k], \n",
    "                   key=lambda k: int(k.split('_d')[1]))\n",
    "for i, key in enumerate(poly_keys[:5]):\n",
    "    pred = results[key]['pred'].reshape(h, w, 3)\n",
    "    axes[1, i].imshow(pred)\n",
    "    deg = key.split('_d')[1]\n",
    "    axes[1, i].set_title(f'Poly deg={deg}\\n{results[key][\"psnr\"]:.1f} dB', fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ngrc_comparison_images.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart by category\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "names = [r[0] for r in sorted_results]\n",
    "psnrs = [r[1]['psnr'] for r in sorted_results]\n",
    "\n",
    "colors = []\n",
    "for n in names:\n",
    "    if 'ngrc_poly' in n:\n",
    "        colors.append('purple')\n",
    "    elif 'fourier' in n:\n",
    "        colors.append('blue')\n",
    "    elif 'random_' in n:\n",
    "        colors.append('orange')\n",
    "    elif 'reservoir' in n:\n",
    "        colors.append('green')\n",
    "    else:\n",
    "        colors.append('gray')\n",
    "\n",
    "bars = ax.bar(range(len(names)), psnrs, color=colors, alpha=0.8)\n",
    "ax.set_xticks(range(len(names)))\n",
    "ax.set_xticklabels(names, rotation=45, ha='right', fontsize=7)\n",
    "ax.set_ylabel('PSNR (dB)', fontsize=12)\n",
    "ax.set_title('NGRC vs Fourier vs Random Projection vs Traditional Reservoir', fontsize=14)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='purple', alpha=0.8, label='NGRC Polynomial'),\n",
    "    Patch(facecolor='blue', alpha=0.8, label='Fourier'),\n",
    "    Patch(facecolor='orange', alpha=0.8, label='Random Projection'),\n",
    "    Patch(facecolor='green', alpha=0.8, label='Traditional Reservoir'),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ngrc_comparison_barchart.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PSNR vs feature dimension for each method\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# NGRC Polynomial\n",
    "poly_data = [(results[k]['dim'], results[k]['psnr']) for k in results if 'ngrc_poly' in k]\n",
    "poly_data.sort()\n",
    "ax.plot([d[0] for d in poly_data], [d[1] for d in poly_data], 'p-', \n",
    "        color='purple', label='NGRC Polynomial', markersize=10, linewidth=2)\n",
    "\n",
    "# Fourier (best sigma)\n",
    "fourier_data = [(results[k]['dim'], results[k]['psnr']) for k in results \n",
    "                if 'fourier' in k and '_s10' in k]  # sigma=10\n",
    "fourier_data.sort()\n",
    "ax.plot([d[0] for d in fourier_data], [d[1] for d in fourier_data], 's-', \n",
    "        color='blue', label='Fourier (σ=10)', markersize=10, linewidth=2)\n",
    "\n",
    "# Random tanh\n",
    "random_data = [(results[k]['dim'], results[k]['psnr']) for k in results \n",
    "               if 'random_tanh' in k]\n",
    "random_data.sort()\n",
    "ax.plot([d[0] for d in random_data], [d[1] for d in random_data], 'o-', \n",
    "        color='orange', label='Random tanh', markersize=10, linewidth=2)\n",
    "\n",
    "# Random sin  \n",
    "random_sin = [(results[k]['dim'], results[k]['psnr']) for k in results \n",
    "              if 'random_sin' in k]\n",
    "random_sin.sort()\n",
    "ax.plot([d[0] for d in random_sin], [d[1] for d in random_sin], '^-', \n",
    "        color='red', label='Random sin', markersize=10, linewidth=2)\n",
    "\n",
    "# Traditional reservoir\n",
    "res_data = [(results[k]['dim'], results[k]['psnr']) for k in results if 'reservoir' in k]\n",
    "for d, p in res_data:\n",
    "    ax.scatter([d], [p], color='green', s=150, marker='*', zorder=5)\n",
    "ax.scatter([], [], color='green', s=150, marker='*', label='Traditional Reservoir')\n",
    "\n",
    "ax.set_xlabel('Feature Dimension', fontsize=12)\n",
    "ax.set_ylabel('PSNR (dB)', fontsize=12)\n",
    "ax.set_title('PSNR vs Feature Dimension', fontsize=14)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ngrc_scaling.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY INSIGHTS: NGRC vs TRADITIONAL APPROACHES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. NGRC PRINCIPLE APPLIED TO INR\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "   NGRC replaces recurrent dynamics with explicit polynomial features.\n",
    "   For spatial INR: polynomial features of (x,y) coordinates.\n",
    "   \n",
    "   This is essentially POLYNOMIAL REGRESSION on coordinates.\n",
    "\n",
    "2. WHY FOURIER STILL WINS\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━\n",
    "   - Natural images are BANDLIMITED (smooth, not polynomial)\n",
    "   - Fourier basis matches image statistics\n",
    "   - Polynomials diverge at boundaries, oscillate badly\n",
    "   - sin/cos are globally smooth and periodic\n",
    "\n",
    "3. WHAT NGRC TEACHES US\n",
    "   ━━━━━━━━━━━━━━━━━━━━\n",
    "   - Recurrence is NOT necessary for good features\n",
    "   - The right BASIS FUNCTION matters more than architecture\n",
    "   - For temporal data: time-delay polynomials work\n",
    "   - For spatial data: Fourier (frequency) basis works\n",
    "\n",
    "4. RANDOM sin(Wx+b) ≈ FOURIER\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "   Random sinusoidal projection approximates Fourier features!\n",
    "   This connects NGRC random projection to Fourier methods.\n",
    "\n",
    "5. RESERVOIR'S REAL VALUE\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━\n",
    "   - NOT in basis function quality\n",
    "   - IN temporal memory and dynamics\n",
    "   - For static INR: use Fourier or NGRC polynomial\n",
    "   - For temporal: use ESN or NGRC time-delay features\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Hybrid NGRC + Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HYBRID: NGRC POLYNOMIAL + FOURIER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine polynomial and Fourier features\n",
    "for poly_deg in [3, 5]:\n",
    "    for fourier_n in [256, 512]:\n",
    "        H_poly_train = ngrc_polynomial_features_fast(train_data[0], poly_deg)\n",
    "        H_poly_test = ngrc_polynomial_features_fast(test_data[0], poly_deg)\n",
    "        \n",
    "        H_fourier_train = fourier_features(train_data[0], fourier_n, sigma=10)\n",
    "        H_fourier_test = fourier_features(test_data[0], fourier_n, sigma=10)\n",
    "        \n",
    "        H_train = np.hstack([H_poly_train, H_fourier_train])\n",
    "        H_test = np.hstack([H_poly_test, H_fourier_test])\n",
    "        \n",
    "        pred, mse, psnr, W = ridge_regression(H_train, train_data[1], H_test, test_data[1])\n",
    "        name = f'hybrid_poly{poly_deg}_fourier{fourier_n}'\n",
    "        results[name] = {'pred': pred, 'mse': mse, 'psnr': psnr, 'dim': H_train.shape[1]}\n",
    "        print(f\"  Poly d={poly_deg} + Fourier n={fourier_n}: PSNR = {psnr:.2f} dB (dim={H_train.shape[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL RANKING (Top 10)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "sorted_all = sorted(results.items(), key=lambda x: x[1]['psnr'], reverse=True)\n",
    "print(f\"{'Rank':<6} {'Method':<40} {'PSNR (dB)':<12} {'Dim':<8}\")\n",
    "print(\"-\" * 66)\n",
    "for i, (name, r) in enumerate(sorted_all[:10]):\n",
    "    print(f\"{i+1:<6} {name:<40} {r['psnr']:<12.2f} {r['dim']:<8}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
