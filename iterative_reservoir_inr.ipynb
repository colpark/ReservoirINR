{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Reservoir INR: Image Generation as Temporal Process\n",
    "\n",
    "**Key Idea**: Generate a spatial image through multiple iterative steps, treating it as a spatiotemporal process.\n",
    "\n",
    "Instead of: `(x,y) → single forward pass → RGB`\n",
    "\n",
    "We do: `(x,y) → step₁ → step₂ → ... → step_K → RGB`\n",
    "\n",
    "This connects to:\n",
    "- **Diffusion models** (iterative denoising)\n",
    "- **Neural ODEs** (continuous dynamics)\n",
    "- **Progressive refinement** (coarse-to-fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    USE_TORCH = True\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"PyTorch available, using {device}\")\n",
    "except ImportError:\n",
    "    USE_TORCH = False\n",
    "    print(\"PyTorch not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "img = Image.open('fig/cat.png').convert('RGB')\n",
    "target_size = 128  # Smaller for faster iteration\n",
    "img = img.resize((target_size, target_size), Image.LANCZOS)\n",
    "img_array = np.array(img) / 255.0\n",
    "\n",
    "h, w, c = img_array.shape\n",
    "coords = np.linspace(0, 1, h, endpoint=False)\n",
    "x_grid = np.stack(np.meshgrid(coords, coords), -1)\n",
    "X = x_grid.reshape(-1, 2)\n",
    "Y = img_array.reshape(-1, 3)\n",
    "\n",
    "print(f\"Image: {h}x{w}, Samples: {len(X)}\")\n",
    "plt.imshow(img_array)\n",
    "plt.title('Target')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Reservoir State Trajectory\n",
    "\n",
    "Use ALL intermediate states, not just final:\n",
    "\n",
    "```\n",
    "h₀ = 0\n",
    "h₁ = tanh(W_in·[x,y] + W_hh·h₀)\n",
    "h₂ = tanh(W_in·[x,y] + W_hh·h₁)\n",
    "...\n",
    "features = [h₁, h₂, ..., h_K]  # Use entire trajectory\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reservoir_trajectory(x, hidden_size, num_steps, spectral_radius=0.95):\n",
    "    \"\"\"\n",
    "    Return the ENTIRE trajectory of reservoir states.\n",
    "    Each step's state can be used to generate an image.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    n, d = x.shape\n",
    "    \n",
    "    # Initialize weights\n",
    "    W_in = np.random.randn(d, hidden_size) * 0.5\n",
    "    W_hh = np.random.randn(hidden_size, hidden_size)\n",
    "    eig = np.abs(np.linalg.eigvals(W_hh)).max()\n",
    "    W_hh = W_hh * (spectral_radius / eig)\n",
    "    b = np.random.randn(hidden_size) * 0.1\n",
    "    \n",
    "    # Collect trajectory for all samples\n",
    "    trajectories = []  # List of (n, hidden_size) arrays, one per step\n",
    "    \n",
    "    H = np.zeros((n, hidden_size))  # Current state\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        H = np.tanh(x @ W_in + H @ W_hh + b)\n",
    "        trajectories.append(H.copy())\n",
    "    \n",
    "    return trajectories, W_in, W_hh, b\n",
    "\n",
    "# Test\n",
    "trajectories, W_in, W_hh, b = reservoir_trajectory(X, hidden_size=256, num_steps=10)\n",
    "print(f\"Generated {len(trajectories)} trajectory steps, each shape: {trajectories[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(H, y, lamb=1e-6):\n",
    "    W = np.linalg.solve(H.T @ H + lamb * np.eye(H.shape[1]), H.T @ y)\n",
    "    return W\n",
    "\n",
    "# Train a separate readout for each step\n",
    "print(\"Training readout for each trajectory step...\")\n",
    "step_images = []\n",
    "step_psnrs = []\n",
    "\n",
    "for i, H in enumerate(trajectories):\n",
    "    W = ridge_regression(H, Y)\n",
    "    pred = np.clip(H @ W, 0, 1)\n",
    "    mse = np.mean((pred - Y) ** 2)\n",
    "    psnr = -10 * np.log10(mse)\n",
    "    step_images.append(pred.reshape(h, w, 3))\n",
    "    step_psnrs.append(psnr)\n",
    "    print(f\"  Step {i+1:2d}: PSNR = {psnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the progressive refinement\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(step_images):\n",
    "        ax.imshow(step_images[i])\n",
    "        ax.set_title(f'Step {i+1}\\n{step_psnrs[i]:.1f} dB')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Reservoir Trajectory: Image at Each Step', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('iterative_trajectory.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Plot PSNR progression\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, len(step_psnrs)+1), step_psnrs, 'bo-', markersize=8)\n",
    "plt.xlabel('Iteration Step')\n",
    "plt.ylabel('PSNR (dB)')\n",
    "plt.title('Image Quality vs Reservoir Iteration')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Cumulative Trajectory Features\n",
    "\n",
    "Instead of separate images per step, concatenate trajectory for richer features:\n",
    "\n",
    "```\n",
    "features = concat([h₁, h₂, ..., h_K])  # K×hidden_size features\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative trajectory features\n",
    "print(\"\\nCumulative Trajectory Features:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "cumulative_results = []\n",
    "\n",
    "for k in [1, 2, 3, 5, 10]:\n",
    "    # Concatenate first k steps\n",
    "    H_cumulative = np.hstack(trajectories[:k])\n",
    "    W = ridge_regression(H_cumulative, Y)\n",
    "    pred = np.clip(H_cumulative @ W, 0, 1)\n",
    "    mse = np.mean((pred - Y) ** 2)\n",
    "    psnr = -10 * np.log10(mse)\n",
    "    cumulative_results.append((k, psnr, pred.reshape(h, w, 3)))\n",
    "    print(f\"  Steps 1-{k:2d} (dim={H_cumulative.shape[1]:4d}): PSNR = {psnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3: Iterative Output Refinement (Diffusion-like)\n",
    "\n",
    "Each step takes the PREVIOUS OUTPUT and refines it:\n",
    "\n",
    "```\n",
    "output₀ = initial_guess (or zeros)\n",
    "output₁ = reservoir(x, y, output₀) \n",
    "output₂ = reservoir(x, y, output₁)\n",
    "...\n",
    "```\n",
    "\n",
    "This is similar to diffusion models / iterative refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_refinement_reservoir(x, y, hidden_size=256, num_iterations=10, \n",
    "                                    spectral_radius=0.9):\n",
    "    \"\"\"\n",
    "    Iterative refinement: each step refines the previous output.\n",
    "    \n",
    "    Input to reservoir at each step: [x, y, current_estimate]\n",
    "    Output: refined_estimate\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    n, d = x.shape\n",
    "    out_dim = y.shape[1]  # 3 for RGB\n",
    "    \n",
    "    # Reservoir weights (input includes coordinates + current estimate)\n",
    "    input_dim = d + out_dim  # x,y + RGB estimate\n",
    "    W_in = np.random.randn(input_dim, hidden_size) * 0.5\n",
    "    W_hh = np.random.randn(hidden_size, hidden_size)\n",
    "    eig = np.abs(np.linalg.eigvals(W_hh)).max()\n",
    "    W_hh = W_hh * (spectral_radius / eig)\n",
    "    b_h = np.random.randn(hidden_size) * 0.1\n",
    "    \n",
    "    # Start with zeros (or could start with noise like diffusion)\n",
    "    current_estimate = np.zeros((n, out_dim))\n",
    "    h = np.zeros((n, hidden_size))\n",
    "    \n",
    "    iteration_outputs = []\n",
    "    iteration_psnrs = []\n",
    "    \n",
    "    for it in range(num_iterations):\n",
    "        # Combine coordinates with current estimate\n",
    "        combined_input = np.hstack([x, current_estimate])\n",
    "        \n",
    "        # Reservoir update\n",
    "        h = np.tanh(combined_input @ W_in + h @ W_hh + b_h)\n",
    "        \n",
    "        # Train readout for this iteration (or use fixed readout)\n",
    "        W_out = ridge_regression(h, y)\n",
    "        current_estimate = np.clip(h @ W_out, 0, 1)\n",
    "        \n",
    "        # Evaluate\n",
    "        mse = np.mean((current_estimate - y) ** 2)\n",
    "        psnr = -10 * np.log10(mse)\n",
    "        \n",
    "        iteration_outputs.append(current_estimate.reshape(h.shape[0]//w, w, out_dim))\n",
    "        iteration_psnrs.append(psnr)\n",
    "    \n",
    "    return iteration_outputs, iteration_psnrs\n",
    "\n",
    "print(\"Iterative Refinement (Diffusion-like):\")\n",
    "print(\"-\" * 40)\n",
    "refine_outputs, refine_psnrs = iterative_refinement_reservoir(X, Y, hidden_size=256, num_iterations=10)\n",
    "\n",
    "for i, psnr in enumerate(refine_psnrs):\n",
    "    print(f\"  Iteration {i+1:2d}: PSNR = {psnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize iterative refinement\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(refine_outputs):\n",
    "        ax.imshow(refine_outputs[i])\n",
    "        ax.set_title(f'Iter {i+1}\\n{refine_psnrs[i]:.1f} dB')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Iterative Refinement: Diffusion-like Image Generation', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('iterative_refinement.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 4: Learned Iterative Refinement (PyTorch)\n",
    "\n",
    "Train a network that explicitly learns to refine over multiple steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TORCH:\n",
    "    class IterativeReservoirINR(nn.Module):\n",
    "        \"\"\"\n",
    "        Learned iterative refinement for image generation.\n",
    "        \n",
    "        Each iteration:\n",
    "        1. Takes (x, y, current_rgb_estimate)\n",
    "        2. Updates hidden state with reservoir-like dynamics\n",
    "        3. Outputs refined RGB estimate\n",
    "        \"\"\"\n",
    "        def __init__(self, hidden_size=256, num_iterations=5):\n",
    "            super().__init__()\n",
    "            self.hidden_size = hidden_size\n",
    "            self.num_iterations = num_iterations\n",
    "            \n",
    "            # Input projection: (x, y, r, g, b) → hidden\n",
    "            self.W_in = nn.Linear(5, hidden_size)\n",
    "            \n",
    "            # Recurrent connection (like reservoir W_hh, but learned)\n",
    "            self.W_hh = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "            \n",
    "            # Output projection: hidden → RGB\n",
    "            self.W_out = nn.Linear(hidden_size, 3)\n",
    "            \n",
    "            # Optional: per-iteration refinement weights\n",
    "            self.refine = nn.Sequential(\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size, 3),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        def forward(self, coords, return_trajectory=False):\n",
    "            \"\"\"\n",
    "            coords: (N, 2) - spatial coordinates\n",
    "            returns: (N, 3) - RGB values, or list of (N, 3) if return_trajectory\n",
    "            \"\"\"\n",
    "            batch_size = coords.shape[0]\n",
    "            \n",
    "            # Initialize\n",
    "            h = torch.zeros(batch_size, self.hidden_size, device=coords.device)\n",
    "            rgb_estimate = torch.zeros(batch_size, 3, device=coords.device)\n",
    "            \n",
    "            trajectory = []\n",
    "            \n",
    "            for it in range(self.num_iterations):\n",
    "                # Combine coords with current estimate\n",
    "                combined = torch.cat([coords, rgb_estimate], dim=-1)  # (N, 5)\n",
    "                \n",
    "                # Reservoir-like update\n",
    "                h = torch.tanh(self.W_in(combined) + self.W_hh(h))\n",
    "                \n",
    "                # Output refinement\n",
    "                rgb_estimate = self.refine(h)\n",
    "                \n",
    "                if return_trajectory:\n",
    "                    trajectory.append(rgb_estimate)\n",
    "            \n",
    "            if return_trajectory:\n",
    "                return trajectory\n",
    "            return rgb_estimate\n",
    "    \n",
    "    print(\"IterativeReservoirINR model defined\")\n",
    "else:\n",
    "    print(\"PyTorch not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TORCH:\n",
    "    # Training\n",
    "    model = IterativeReservoirINR(hidden_size=256, num_iterations=5).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    X_t = torch.FloatTensor(X).to(device)\n",
    "    Y_t = torch.FloatTensor(Y).to(device)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    print(\"Training Iterative Reservoir INR...\")\n",
    "    for epoch in tqdm(range(1000)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get trajectory of outputs\n",
    "        trajectory = model(X_t, return_trajectory=True)\n",
    "        \n",
    "        # Loss on ALL iterations (encourages progressive refinement)\n",
    "        loss = 0\n",
    "        for it, pred in enumerate(trajectory):\n",
    "            # Weight later iterations more\n",
    "            weight = (it + 1) / len(trajectory)\n",
    "            loss += weight * torch.mean((pred - Y_t) ** 2)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    print(f\"Final loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TORCH:\n",
    "    # Visualize learned iterative refinement\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        trajectory = model(X_t, return_trajectory=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(trajectory) + 1, figsize=(15, 3))\n",
    "    \n",
    "    axes[0].imshow(img_array)\n",
    "    axes[0].set_title('Target')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    for i, pred in enumerate(trajectory):\n",
    "        pred_img = pred.cpu().numpy().reshape(h, w, 3)\n",
    "        mse = np.mean((pred_img - img_array) ** 2)\n",
    "        psnr = -10 * np.log10(mse)\n",
    "        \n",
    "        axes[i+1].imshow(pred_img)\n",
    "        axes[i+1].set_title(f'Iter {i+1}\\n{psnr:.1f} dB')\n",
    "        axes[i+1].axis('off')\n",
    "    \n",
    "    plt.suptitle('Learned Iterative Refinement', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('learned_iterative_refinement.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 5: Multi-Scale Iterative (Coarse-to-Fine)\n",
    "\n",
    "Different iterations focus on different frequency scales:\n",
    "- Early iterations: low frequency (coarse structure)\n",
    "- Later iterations: high frequency (fine details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiscale_iterative_reservoir(x, y, hidden_size=256, num_scales=5):\n",
    "    \"\"\"\n",
    "    Each scale uses different spectral radius (controls frequency).\n",
    "    Low spectral radius → smooth/low-freq\n",
    "    High spectral radius → detailed/high-freq\n",
    "    \"\"\"\n",
    "    n, d = x.shape\n",
    "    \n",
    "    # Different spectral radii for different scales\n",
    "    spectral_radii = np.linspace(0.5, 0.99, num_scales)\n",
    "    \n",
    "    scale_outputs = []\n",
    "    cumulative_output = np.zeros_like(y)\n",
    "    \n",
    "    for scale_idx, sr in enumerate(spectral_radii):\n",
    "        np.random.seed(42 + scale_idx)\n",
    "        \n",
    "        # Reservoir for this scale\n",
    "        W_in = np.random.randn(d, hidden_size) * 0.5\n",
    "        W_hh = np.random.randn(hidden_size, hidden_size)\n",
    "        eig = np.abs(np.linalg.eigvals(W_hh)).max()\n",
    "        W_hh = W_hh * (sr / eig)\n",
    "        b = np.random.randn(hidden_size) * 0.1\n",
    "        \n",
    "        # Run reservoir\n",
    "        h = np.zeros((n, hidden_size))\n",
    "        for _ in range(5):  # A few iterations per scale\n",
    "            h = np.tanh(x @ W_in + h @ W_hh + b)\n",
    "        \n",
    "        # Predict RESIDUAL (what's missing from current estimate)\n",
    "        residual_target = y - cumulative_output\n",
    "        W_out = ridge_regression(h, residual_target)\n",
    "        residual_pred = h @ W_out\n",
    "        \n",
    "        # Add to cumulative\n",
    "        cumulative_output = np.clip(cumulative_output + residual_pred, 0, 1)\n",
    "        \n",
    "        mse = np.mean((cumulative_output - y) ** 2)\n",
    "        psnr = -10 * np.log10(mse)\n",
    "        scale_outputs.append((cumulative_output.copy(), psnr, sr))\n",
    "        print(f\"  Scale {scale_idx+1} (ρ={sr:.2f}): PSNR = {psnr:.2f} dB\")\n",
    "    \n",
    "    return scale_outputs\n",
    "\n",
    "print(\"\\nMulti-Scale Iterative (Coarse-to-Fine):\")\n",
    "print(\"-\" * 40)\n",
    "multiscale_outputs = multiscale_iterative_reservoir(X, Y, hidden_size=256, num_scales=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multi-scale progression\n",
    "fig, axes = plt.subplots(1, len(multiscale_outputs) + 1, figsize=(15, 3))\n",
    "\n",
    "axes[0].imshow(img_array)\n",
    "axes[0].set_title('Target')\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i, (output, psnr, sr) in enumerate(multiscale_outputs):\n",
    "    axes[i+1].imshow(output.reshape(h, w, 3))\n",
    "    axes[i+1].set_title(f'Scale {i+1} (ρ={sr:.2f})\\n{psnr:.1f} dB')\n",
    "    axes[i+1].axis('off')\n",
    "\n",
    "plt.suptitle('Multi-Scale Reservoir: Coarse-to-Fine Refinement', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('multiscale_refinement.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: All Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with Fourier baseline\n",
    "def fourier_features(x, num_features, sigma):\n",
    "    np.random.seed(42)\n",
    "    B = np.random.randn(num_features, x.shape[1]) * sigma\n",
    "    x_proj = (2. * np.pi * x) @ B.T\n",
    "    return np.concatenate([np.sin(x_proj), np.cos(x_proj)], axis=-1)\n",
    "\n",
    "H_fourier = fourier_features(X, 256, sigma=10)\n",
    "W_fourier = ridge_regression(H_fourier, Y)\n",
    "pred_fourier = np.clip(H_fourier @ W_fourier, 0, 1)\n",
    "mse_fourier = np.mean((pred_fourier - Y) ** 2)\n",
    "psnr_fourier = -10 * np.log10(mse_fourier)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON: ALL APPROACHES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nFourier Features (baseline):        {psnr_fourier:.2f} dB\")\n",
    "print(f\"Reservoir Trajectory (best step):   {max(step_psnrs):.2f} dB\")\n",
    "print(f\"Cumulative Trajectory (all steps):  {cumulative_results[-1][1]:.2f} dB\")\n",
    "print(f\"Iterative Refinement (final):       {refine_psnrs[-1]:.2f} dB\")\n",
    "print(f\"Multi-Scale (final):                {multiscale_outputs[-1][1]:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison visualization\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "axes[0, 0].imshow(img_array)\n",
    "axes[0, 0].set_title('Target', fontsize=12)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(pred_fourier.reshape(h, w, 3))\n",
    "axes[0, 1].set_title(f'Fourier\\n{psnr_fourier:.1f} dB', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "best_step_idx = np.argmax(step_psnrs)\n",
    "axes[0, 2].imshow(step_images[best_step_idx])\n",
    "axes[0, 2].set_title(f'Best Trajectory Step\\n{step_psnrs[best_step_idx]:.1f} dB', fontsize=12)\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[0, 3].imshow(cumulative_results[-1][2])\n",
    "axes[0, 3].set_title(f'Cumulative Trajectory\\n{cumulative_results[-1][1]:.1f} dB', fontsize=12)\n",
    "axes[0, 3].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(refine_outputs[-1])\n",
    "axes[1, 0].set_title(f'Iterative Refinement\\n{refine_psnrs[-1]:.1f} dB', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(multiscale_outputs[-1][0].reshape(h, w, 3))\n",
    "axes[1, 1].set_title(f'Multi-Scale\\n{multiscale_outputs[-1][1]:.1f} dB', fontsize=12)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Plot progression curves\n",
    "ax = axes[1, 2]\n",
    "ax.plot(range(1, len(step_psnrs)+1), step_psnrs, 'o-', label='Trajectory')\n",
    "ax.plot(range(1, len(refine_psnrs)+1), refine_psnrs, 's-', label='Iterative')\n",
    "ax.plot(range(1, len(multiscale_outputs)+1), [x[1] for x in multiscale_outputs], '^-', label='Multi-Scale')\n",
    "ax.axhline(psnr_fourier, color='r', linestyle='--', label='Fourier')\n",
    "ax.set_xlabel('Step/Scale')\n",
    "ax.set_ylabel('PSNR (dB)')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_title('Progression Curves')\n",
    "\n",
    "axes[1, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('iterative_reservoir_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "══════════════════════════════════════════════════════════════════════\n",
    "                    KEY INSIGHTS: ITERATIVE RESERVOIR INR\n",
    "══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "1. TRAJECTORY AS FEATURES\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━\n",
    "   Using ALL reservoir states (not just final) provides richer features.\n",
    "   Each step captures different aspects of the input.\n",
    "   Cumulative trajectory often beats single-step.\n",
    "\n",
    "2. ITERATIVE REFINEMENT\n",
    "   ━━━━━━━━━━━━━━━━━━━━\n",
    "   Like diffusion models: start with coarse estimate, refine progressively.\n",
    "   Each iteration sees (coordinates + current_estimate) → refined_estimate.\n",
    "   Natural way to incorporate feedback / error correction.\n",
    "\n",
    "3. MULTI-SCALE / COARSE-TO-FINE\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "   Different spectral radii → different frequency responses.\n",
    "   Low ρ: smooth, coarse structure\n",
    "   High ρ: detailed, fine structure\n",
    "   Predicting residuals at each scale is effective.\n",
    "\n",
    "4. WHEN ITERATIVE HELPS\n",
    "   ━━━━━━━━━━━━━━━━━━━━\n",
    "   ✓ When data has hierarchical structure (coarse → fine)\n",
    "   ✓ When refinement makes sense conceptually\n",
    "   ✓ For complex outputs requiring multiple \"passes\"\n",
    "   ✗ For simple mappings, single-pass may suffice\n",
    "\n",
    "5. CONNECTION TO OTHER METHODS\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "   - Diffusion Models: iterative denoising\n",
    "   - Neural ODEs: continuous-depth networks  \n",
    "   - Recurrent refinement: iterative inference\n",
    "   - Cascade networks: coarse-to-fine prediction\n",
    "\n",
    "══════════════════════════════════════════════════════════════════════\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
