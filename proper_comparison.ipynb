{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper Fourier Features vs Reservoir Comparison\n",
    "\n",
    "Following the exact implementation from fourier-feature-networks/Demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Try JAX first (as in original), fall back to NumPy\n",
    "try:\n",
    "    import jax.numpy as jnp\n",
    "    from jax import jit, grad, random\n",
    "    from jax.example_libraries import stax, optimizers\n",
    "    USE_JAX = True\n",
    "    print(\"Using JAX\")\n",
    "except ImportError:\n",
    "    USE_JAX = False\n",
    "    print(\"JAX not available, using NumPy + PyTorch\")\n",
    "    try:\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        USE_TORCH = True\n",
    "        print(\"Using PyTorch for MLP training\")\n",
    "    except ImportError:\n",
    "        USE_TORCH = False\n",
    "        print(\"PyTorch not available, using Ridge regression only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cat image\n",
    "img = Image.open('fig/cat.png').convert('RGB')\n",
    "print(f\"Original size: {img.size}\")\n",
    "\n",
    "# Resize for computation\n",
    "target_size = 256  # Larger than before\n",
    "img = img.resize((target_size, target_size), Image.LANCZOS)\n",
    "img_array = np.array(img) / 255.0\n",
    "\n",
    "h, w, c = img_array.shape\n",
    "print(f\"Resized to: {h}x{w}x{c}\")\n",
    "\n",
    "# Create coordinate grid (exactly as in Demo.ipynb)\n",
    "coords = np.linspace(0, 1, h, endpoint=False)\n",
    "x_test = np.stack(np.meshgrid(coords, coords), -1)  # (H, W, 2)\n",
    "\n",
    "# Full resolution for testing, half for training\n",
    "test_data = (x_test.reshape(-1, 2), img_array.reshape(-1, 3))\n",
    "train_data = (x_test[::2, ::2].reshape(-1, 2), img_array[::2, ::2].reshape(-1, 3))\n",
    "\n",
    "print(f\"Train samples: {len(train_data[0])}, Test samples: {len(test_data[0])}\")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img_array)\n",
    "plt.title(f'Target Image ({h}x{w})')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Feature Mapping (Exactly as in Demo.ipynb)\n",
    "\n",
    "$$\\gamma(\\mathbf{v}) = \\left[ \\cos(2\\pi \\mathbf{B} \\mathbf{v}), \\sin(2\\pi \\mathbf{B} \\mathbf{v}) \\right]^T$$\n",
    "\n",
    "where $\\mathbf{B} \\in \\mathbb{R}^{m \\times d}$ is sampled from $\\mathcal{N}(0, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_mapping(x, B):\n",
    "    \"\"\"Fourier feature mapping exactly as in the paper.\"\"\"\n",
    "    if B is None:\n",
    "        return x\n",
    "    x_proj = (2. * np.pi * x) @ B.T  # (N, m)\n",
    "    return np.concatenate([np.sin(x_proj), np.cos(x_proj)], axis=-1)  # (N, 2m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Reservoir Feature Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_reservoir(x, hidden_size, num_layers=5, iterations=10, spectral_radius=0.9):\n",
    "    \"\"\"Deep stacked reservoir with recurrence at each layer.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n, d = x.shape\n",
    "    \n",
    "    # Build layers\n",
    "    layers = []\n",
    "    d_in = d\n",
    "    for layer in range(num_layers):\n",
    "        np.random.seed(42 + layer)\n",
    "        W_in = np.random.randn(d_in, hidden_size) * 0.5\n",
    "        W_hh = np.random.randn(hidden_size, hidden_size)\n",
    "        eig = np.abs(np.linalg.eigvals(W_hh)).max()\n",
    "        W_hh = W_hh * (spectral_radius / eig)\n",
    "        b = np.random.randn(hidden_size) * 0.1\n",
    "        layers.append((W_in, W_hh, b))\n",
    "        d_in = hidden_size\n",
    "    \n",
    "    # Process each sample\n",
    "    all_states = []\n",
    "    for i in tqdm(range(n), desc='Reservoir', leave=False):\n",
    "        layer_input = x[i:i+1]\n",
    "        layer_states = []\n",
    "        \n",
    "        for W_in, W_hh, b in layers:\n",
    "            h = np.zeros(hidden_size)\n",
    "            for _ in range(iterations):\n",
    "                h = np.tanh(layer_input @ W_in + h @ W_hh + b).flatten()\n",
    "            layer_states.append(h)\n",
    "            layer_input = h.reshape(1, -1)\n",
    "        \n",
    "        all_states.append(np.concatenate(layer_states))\n",
    "    \n",
    "    return np.array(all_states)\n",
    "\n",
    "\n",
    "def stacked_random(x, hidden_size, num_layers=5):\n",
    "    \"\"\"Stacked random projections WITHOUT recurrence (control).\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n, d = x.shape\n",
    "    \n",
    "    all_features = []\n",
    "    h = x\n",
    "    d_in = d\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        np.random.seed(42 + layer)\n",
    "        W = np.random.randn(d_in, hidden_size) * np.sqrt(2.0 / d_in)\n",
    "        b = np.random.randn(hidden_size) * 0.1\n",
    "        h = np.tanh(h @ W + b)\n",
    "        all_features.append(h)\n",
    "        d_in = hidden_size\n",
    "    \n",
    "    return np.concatenate(all_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model (PyTorch version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TORCH:\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim=256, num_layers=4):\n",
    "            super().__init__()\n",
    "            layers = []\n",
    "            d_in = input_dim\n",
    "            for i in range(num_layers - 1):\n",
    "                layers.append(nn.Linear(d_in, hidden_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                d_in = hidden_dim\n",
    "            layers.append(nn.Linear(d_in, 3))\n",
    "            layers.append(nn.Sigmoid())\n",
    "            self.net = nn.Sequential(*layers)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "    \n",
    "    def train_mlp(H_train, y_train, H_test, y_test, num_layers=4, hidden_dim=256, \n",
    "                  lr=1e-4, iters=2000, device='cuda'):\n",
    "        \"\"\"Train MLP exactly as in Demo.ipynb.\"\"\"\n",
    "        if not torch.cuda.is_available():\n",
    "            device = 'cpu'\n",
    "        \n",
    "        model = MLP(H_train.shape[1], hidden_dim, num_layers).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        H_train_t = torch.FloatTensor(H_train).to(device)\n",
    "        y_train_t = torch.FloatTensor(y_train).to(device)\n",
    "        H_test_t = torch.FloatTensor(H_test).to(device)\n",
    "        y_test_t = torch.FloatTensor(y_test).to(device)\n",
    "        \n",
    "        train_psnrs, test_psnrs = [], []\n",
    "        \n",
    "        for i in tqdm(range(iters), desc='Training', leave=False):\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(H_train_t)\n",
    "            loss = 0.5 * torch.mean((pred - y_train_t) ** 2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % 50 == 0:\n",
    "                with torch.no_grad():\n",
    "                    train_mse = torch.mean((model(H_train_t) - y_train_t) ** 2).item()\n",
    "                    test_mse = torch.mean((model(H_test_t) - y_test_t) ** 2).item()\n",
    "                    train_psnrs.append(-10 * np.log10(train_mse))\n",
    "                    test_psnrs.append(-10 * np.log10(test_mse))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(H_test_t).cpu().numpy()\n",
    "            mse = np.mean((pred - y_test) ** 2)\n",
    "            psnr = -10 * np.log10(mse)\n",
    "        \n",
    "        return pred, mse, psnr, train_psnrs, test_psnrs\n",
    "else:\n",
    "    print(\"MLP training not available without PyTorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression (Fast baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(H_train, y_train, H_test, y_test, lamb=1e-6):\n",
    "    \"\"\"Simple ridge regression.\"\"\"\n",
    "    W = np.linalg.solve(H_train.T @ H_train + lamb * np.eye(H_train.shape[1]), H_train.T @ y_train)\n",
    "    pred = np.clip(H_test @ W, 0, 1)\n",
    "    mse = np.mean((pred - y_test) ** 2)\n",
    "    psnr = -10 * np.log10(mse) if mse > 0 else 100\n",
    "    return pred, mse, psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Fourier Features (as in Demo.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create B matrix as in Demo.ipynb\n",
    "np.random.seed(0)  # Match the paper\n",
    "mapping_size = 256\n",
    "B_gauss = np.random.randn(mapping_size, 2)\n",
    "\n",
    "# Test different scales as in Demo.ipynb\n",
    "B_dict = {\n",
    "    'none': None,\n",
    "    'basic': np.eye(2),\n",
    "    'gauss_1': B_gauss * 1.,\n",
    "    'gauss_10': B_gauss * 10.,\n",
    "    'gauss_100': B_gauss * 100.,\n",
    "}\n",
    "\n",
    "# Also test larger mapping\n",
    "np.random.seed(0)\n",
    "B_large = np.random.randn(1024, 2)\n",
    "B_dict['gauss_10_large'] = B_large * 10.\n",
    "B_dict['gauss_100_large'] = B_large * 100.\n",
    "\n",
    "print(\"Fourier feature configurations:\")\n",
    "for k, B in B_dict.items():\n",
    "    if B is None:\n",
    "        print(f\"  {k}: dim=2 (raw coords)\")\n",
    "    else:\n",
    "        H = input_mapping(train_data[0][:1], B)\n",
    "        print(f\"  {k}: dim={H.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Fourier experiments with Ridge regression\n",
    "fourier_results = {}\n",
    "\n",
    "print(\"Fourier Features with Ridge Regression:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, B in tqdm(B_dict.items(), desc='Fourier'):\n",
    "    H_train = input_mapping(train_data[0], B)\n",
    "    H_test = input_mapping(test_data[0], B)\n",
    "    \n",
    "    pred, mse, psnr = ridge_regression(H_train, train_data[1], H_test, test_data[1])\n",
    "    fourier_results[f'fourier_{name}_ridge'] = {\n",
    "        'pred': pred, 'mse': mse, 'psnr': psnr, \n",
    "        'dim': H_train.shape[1], 'B': B\n",
    "    }\n",
    "    print(f\"  {name:<20}: PSNR = {psnr:.2f} dB (dim={H_train.shape[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Fourier experiments with MLP (if PyTorch available)\n",
    "if USE_TORCH:\n",
    "    print(\"\\nFourier Features with MLP (as in original paper):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for name in ['none', 'gauss_1', 'gauss_10', 'gauss_100']:\n",
    "        B = B_dict[name]\n",
    "        H_train = input_mapping(train_data[0], B)\n",
    "        H_test = input_mapping(test_data[0], B)\n",
    "        \n",
    "        print(f\"  Training {name}...\")\n",
    "        pred, mse, psnr, train_psnrs, test_psnrs = train_mlp(\n",
    "            H_train, train_data[1], H_test, test_data[1],\n",
    "            num_layers=4, hidden_dim=256, lr=1e-4, iters=2000\n",
    "        )\n",
    "        fourier_results[f'fourier_{name}_mlp'] = {\n",
    "            'pred': pred, 'mse': mse, 'psnr': psnr,\n",
    "            'dim': H_train.shape[1], 'train_psnrs': train_psnrs, 'test_psnrs': test_psnrs\n",
    "        }\n",
    "        print(f\"    {name:<20}: PSNR = {psnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Reservoir Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir_results = {}\n",
    "\n",
    "print(\"Deep Reservoir with Ridge Regression:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "configs = [\n",
    "    (5, 64),   # 5 layers, 64 hidden -> dim=320\n",
    "    (5, 128),  # 5 layers, 128 hidden -> dim=640\n",
    "    (10, 64),  # 10 layers, 64 hidden -> dim=640\n",
    "    (10, 128), # 10 layers, 128 hidden -> dim=1280\n",
    "    (20, 64),  # 20 layers, 64 hidden -> dim=1280\n",
    "]\n",
    "\n",
    "for num_layers, hidden in configs:\n",
    "    name = f'L{num_layers}_H{hidden}'\n",
    "    print(f\"  Computing {name}...\")\n",
    "    \n",
    "    H_train = deep_reservoir(train_data[0], hidden, num_layers=num_layers, iterations=10)\n",
    "    H_test = deep_reservoir(test_data[0], hidden, num_layers=num_layers, iterations=10)\n",
    "    \n",
    "    pred, mse, psnr = ridge_regression(H_train, train_data[1], H_test, test_data[1])\n",
    "    reservoir_results[f'reservoir_{name}_ridge'] = {\n",
    "        'pred': pred, 'mse': mse, 'psnr': psnr, 'dim': H_train.shape[1]\n",
    "    }\n",
    "    print(f\"    {name:<15}: PSNR = {psnr:.2f} dB (dim={H_train.shape[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reservoir with MLP (if PyTorch available)\n",
    "if USE_TORCH:\n",
    "    print(\"\\nDeep Reservoir with MLP:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for num_layers, hidden in [(5, 128), (10, 128)]:\n",
    "        name = f'L{num_layers}_H{hidden}'\n",
    "        print(f\"  Training {name}...\")\n",
    "        \n",
    "        H_train = deep_reservoir(train_data[0], hidden, num_layers=num_layers, iterations=10)\n",
    "        H_test = deep_reservoir(test_data[0], hidden, num_layers=num_layers, iterations=10)\n",
    "        \n",
    "        pred, mse, psnr, train_psnrs, test_psnrs = train_mlp(\n",
    "            H_train, train_data[1], H_test, test_data[1],\n",
    "            num_layers=4, hidden_dim=256, lr=1e-4, iters=2000\n",
    "        )\n",
    "        reservoir_results[f'reservoir_{name}_mlp'] = {\n",
    "            'pred': pred, 'mse': mse, 'psnr': psnr,\n",
    "            'dim': H_train.shape[1], 'train_psnrs': train_psnrs, 'test_psnrs': test_psnrs\n",
    "        }\n",
    "        print(f\"    {name:<15}: PSNR = {psnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Stacked Random (Control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_results = {}\n",
    "\n",
    "print(\"Stacked Random (No Recurrence) with Ridge:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for num_layers, hidden in [(5, 128), (10, 128), (20, 64)]:\n",
    "    name = f'L{num_layers}_H{hidden}'\n",
    "    \n",
    "    H_train = stacked_random(train_data[0], hidden, num_layers=num_layers)\n",
    "    H_test = stacked_random(test_data[0], hidden, num_layers=num_layers)\n",
    "    \n",
    "    pred, mse, psnr = ridge_regression(H_train, train_data[1], H_test, test_data[1])\n",
    "    stacked_results[f'stacked_{name}_ridge'] = {\n",
    "        'pred': pred, 'mse': mse, 'psnr': psnr, 'dim': H_train.shape[1]\n",
    "    }\n",
    "    print(f\"  {name:<15}: PSNR = {psnr:.2f} dB (dim={H_train.shape[1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "all_results = {**fourier_results, **reservoir_results, **stacked_results}\n",
    "\n",
    "# Sort by PSNR\n",
    "sorted_results = sorted(all_results.items(), key=lambda x: x[1]['psnr'], reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL RESULTS (sorted by PSNR)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Method':<40} {'PSNR (dB)':<12} {'Dim':<8}\")\n",
    "print(\"-\" * 60)\n",
    "for name, r in sorted_results:\n",
    "    print(f\"{name:<40} {r['psnr']:<12.2f} {r['dim']:<8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best in each category\n",
    "best_fourier = max([k for k in all_results if 'fourier' in k], key=lambda k: all_results[k]['psnr'])\n",
    "best_reservoir = max([k for k in all_results if 'reservoir' in k], key=lambda k: all_results[k]['psnr'])\n",
    "best_stacked = max([k for k in all_results if 'stacked' in k], key=lambda k: all_results[k]['psnr'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BEST IN EACH CATEGORY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Best Fourier:   {best_fourier:<30} PSNR = {all_results[best_fourier]['psnr']:.2f} dB\")\n",
    "print(f\"Best Reservoir: {best_reservoir:<30} PSNR = {all_results[best_reservoir]['psnr']:.2f} dB\")\n",
    "print(f\"Best Stacked:   {best_stacked:<30} PSNR = {all_results[best_stacked]['psnr']:.2f} dB\")\n",
    "print(\"\\nGaps:\")\n",
    "print(f\"  Fourier - Reservoir: {all_results[best_fourier]['psnr'] - all_results[best_reservoir]['psnr']:.2f} dB\")\n",
    "print(f\"  Reservoir - Stacked: {all_results[best_reservoir]['psnr'] - all_results[best_stacked]['psnr']:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "\n",
    "# Row 1: Best results\n",
    "axes[0, 0].imshow(img_array)\n",
    "axes[0, 0].set_title('Original', fontsize=12)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "pred = all_results[best_fourier]['pred'].reshape(h, w, 3)\n",
    "axes[0, 1].imshow(pred)\n",
    "axes[0, 1].set_title(f'Best Fourier\\n{all_results[best_fourier][\"psnr\"]:.1f} dB', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "pred = all_results[best_reservoir]['pred'].reshape(h, w, 3)\n",
    "axes[0, 2].imshow(pred)\n",
    "axes[0, 2].set_title(f'Best Reservoir\\n{all_results[best_reservoir][\"psnr\"]:.1f} dB', fontsize=12)\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "pred = all_results[best_stacked]['pred'].reshape(h, w, 3)\n",
    "axes[0, 3].imshow(pred)\n",
    "axes[0, 3].set_title(f'Best Stacked\\n{all_results[best_stacked][\"psnr\"]:.1f} dB', fontsize=12)\n",
    "axes[0, 3].axis('off')\n",
    "\n",
    "if 'fourier_none_ridge' in all_results:\n",
    "    pred = all_results['fourier_none_ridge']['pred'].reshape(h, w, 3)\n",
    "    axes[0, 4].imshow(pred)\n",
    "    axes[0, 4].set_title(f'No Mapping\\n{all_results[\"fourier_none_ridge\"][\"psnr\"]:.1f} dB', fontsize=12)\n",
    "    axes[0, 4].axis('off')\n",
    "\n",
    "# Row 2: Fourier scale comparison\n",
    "for i, scale in enumerate(['1', '10', '100']):\n",
    "    key = f'fourier_gauss_{scale}_ridge'\n",
    "    if key in all_results:\n",
    "        pred = all_results[key]['pred'].reshape(h, w, 3)\n",
    "        axes[1, i].imshow(pred)\n",
    "        axes[1, i].set_title(f'Fourier σ={scale}\\n{all_results[key][\"psnr\"]:.1f} dB', fontsize=12)\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "# Large Fourier\n",
    "if 'fourier_gauss_10_large_ridge' in all_results:\n",
    "    pred = all_results['fourier_gauss_10_large_ridge']['pred'].reshape(h, w, 3)\n",
    "    axes[1, 3].imshow(pred)\n",
    "    axes[1, 3].set_title(f'Fourier σ=10 (large)\\n{all_results[\"fourier_gauss_10_large_ridge\"][\"psnr\"]:.1f} dB', fontsize=12)\n",
    "    axes[1, 3].axis('off')\n",
    "\n",
    "if 'fourier_gauss_100_large_ridge' in all_results:\n",
    "    pred = all_results['fourier_gauss_100_large_ridge']['pred'].reshape(h, w, 3)\n",
    "    axes[1, 4].imshow(pred)\n",
    "    axes[1, 4].set_title(f'Fourier σ=100 (large)\\n{all_results[\"fourier_gauss_100_large_ridge\"][\"psnr\"]:.1f} dB', fontsize=12)\n",
    "    axes[1, 4].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('proper_comparison_images.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "names = [r[0] for r in sorted_results]\n",
    "psnrs = [r[1]['psnr'] for r in sorted_results]\n",
    "\n",
    "colors = []\n",
    "for n in names:\n",
    "    if 'fourier' in n and 'mlp' in n:\n",
    "        colors.append('darkblue')\n",
    "    elif 'fourier' in n:\n",
    "        colors.append('lightblue')\n",
    "    elif 'reservoir' in n and 'mlp' in n:\n",
    "        colors.append('darkgreen')\n",
    "    elif 'reservoir' in n:\n",
    "        colors.append('lightgreen')\n",
    "    elif 'stacked' in n:\n",
    "        colors.append('orange')\n",
    "    else:\n",
    "        colors.append('gray')\n",
    "\n",
    "bars = ax.bar(range(len(names)), psnrs, color=colors, alpha=0.8)\n",
    "ax.set_xticks(range(len(names)))\n",
    "ax.set_xticklabels(names, rotation=45, ha='right', fontsize=8)\n",
    "ax.set_ylabel('PSNR (dB)', fontsize=12)\n",
    "ax.set_title('Fourier vs Reservoir vs Stacked Random (Cat Image INR)', fontsize=14)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='darkblue', alpha=0.8, label='Fourier + MLP'),\n",
    "    Patch(facecolor='lightblue', alpha=0.8, label='Fourier + Ridge'),\n",
    "    Patch(facecolor='darkgreen', alpha=0.8, label='Reservoir + MLP'),\n",
    "    Patch(facecolor='lightgreen', alpha=0.8, label='Reservoir + Ridge'),\n",
    "    Patch(facecolor='orange', alpha=0.8, label='Stacked Random'),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('proper_comparison_barchart.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves (if MLP results available)\n",
    "mlp_results = {k: v for k, v in all_results.items() if 'train_psnrs' in v}\n",
    "\n",
    "if mlp_results:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    for name, r in mlp_results.items():\n",
    "        short_name = name.replace('fourier_', 'F:').replace('reservoir_', 'R:').replace('_mlp', '')\n",
    "        xs = np.arange(0, len(r['train_psnrs'])) * 50\n",
    "        axes[0].plot(xs, r['train_psnrs'], label=short_name)\n",
    "        axes[1].plot(xs, r['test_psnrs'], label=short_name)\n",
    "    \n",
    "    axes[0].set_xlabel('Iteration')\n",
    "    axes[0].set_ylabel('PSNR (dB)')\n",
    "    axes[0].set_title('Train PSNR')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].set_xlabel('Iteration')\n",
    "    axes[1].set_ylabel('PSNR (dB)')\n",
    "    axes[1].set_title('Test PSNR')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('proper_comparison_training.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONCLUSIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Following the exact implementation from fourier-feature-networks/Demo.ipynb:\n",
    "\n",
    "1. FOURIER FEATURE MAPPING\n",
    "   γ(v) = [sin(2πBv), cos(2πBv)]^T where B ~ N(0, σ²)\n",
    "   \n",
    "   - Scale (σ) is CRITICAL: σ=1 underfits, σ=100 can overfit\n",
    "   - Best scale typically σ=10-100 for natural images\n",
    "   - Larger mapping_size (1024 vs 256) helps\n",
    "\n",
    "2. DEEP RESERVOIR\n",
    "   - Recurrence DOES add value over stacked random (+2-3 dB)\n",
    "   - But still fundamentally limited for static coordinate mapping\n",
    "   - More layers/hidden units help, but hit diminishing returns\n",
    "\n",
    "3. KEY FINDINGS\n",
    "   - Fourier features are fundamentally better for INR tasks\n",
    "   - Gap persists regardless of decoder (Ridge vs MLP)\n",
    "   - Reservoir's strength is temporal memory, not basis quality\n",
    "   \n",
    "4. WHY FOURIER WINS FOR STATIC INR\n",
    "   - Fourier basis: smooth, continuous, frequency-selective\n",
    "   - Natural images are bandlimited → perfect match\n",
    "   - Reservoir: designed for temporal dynamics, not spatial patterns\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
